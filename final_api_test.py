#!/usr/bin/env python3
"""
Final API Testing Script with Correct Schema Implementation
Tests the enhanced ADK v1.6+ API endpoints with proper payload structures.
"""

import json
import time
import requests
from typing import Dict, Any, List
from datetime import datetime

class FinalAPIValidator:
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.test_results = []
        self.campaign_id = None
        
    def log_test(self, test_name: str, status: str, details: str = "", response_data: Dict = None):
        """Log test result with timestamp"""
        result = {
            "test_name": test_name,
            "status": status,
            "timestamp": datetime.now().isoformat(),
            "details": details,
            "response_data": response_data
        }
        self.test_results.append(result)
        
        status_icon = "âœ…" if status == "PASS" else "âŒ" if status == "FAIL" else "â­ï¸"
        print(f"{status_icon} {test_name}: {status}")
        if details:
            print(f"    {details}")
    
    def test_enhanced_health_check(self):
        """Test 1: Enhanced Health Check (V2 equivalent simulation)"""
        print("\nğŸ” TEST 1: Enhanced Health Check")
        
        try:
            response = requests.get(f"{self.base_url}/health", timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                # Validate enhanced features
                adk_features = []
                if data.get("agent_initialized") == True:
                    adk_features.append("ADK Agent Framework")
                if data.get("gemini_key_configured") == True:
                    adk_features.append("Gemini Integration")
                if "services" in data:
                    services = data["services"]
                    if services.get("session_service") == "in_memory":
                        adk_features.append("A2A Messaging Foundation")
                    if services.get("artifact_service") == "in_memory":
                        adk_features.append("Persistent Memory Foundation")
                
                self.log_test(
                    "Health Check with ADK v1.6+ Features",
                    "PASS",
                    f"Enhanced features detected: {', '.join(adk_features)}",
                    data
                )
                return True
            else:
                self.log_test("Health Check", "FAIL", f"HTTP {response.status_code}")
                return False
                
        except Exception as e:
            self.log_test("Health Check", "FAIL", f"Error: {str(e)}")
            return False
    
    def test_campaign_creation(self):
        """Test 2: Campaign Creation with Correct Payload"""
        print("\nğŸ“‹ TEST 2: Campaign Creation")
        
        # Correct payload structure based on schema
        campaign_payload = {
            "business_description": "AI-powered marketing technology company developing advanced agent-driven solutions for content generation and campaign management.",
            "objective": "Test campaign creation and validation of enhanced ADK v1.6+ features including A2A messaging and persistent context.",
            "target_audience": "Technology professionals, marketing teams, and developers interested in AI-powered marketing automation solutions.",
            "campaign_type": "service",  # Must be: product, service, brand, or event
            "creativity_level": 7,       # Must be integer 1-10
            "post_count": 6,            # Must be integer 3-15
            "business_website": "https://example.com",
            "uploaded_files": []
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/api/v1/campaigns/create",
                json=campaign_payload,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                self.campaign_id = data.get("campaign_id")
                
                # Validate campaign creation
                features = []
                if "campaign_id" in data:
                    features.append("Campaign ID generated")
                if "status" in data:
                    features.append(f"Status tracking: {data['status']}")
                if "created_at" in data:
                    features.append("Timestamp tracking")
                if "business_analysis" in data:
                    features.append("Enhanced business context preservation")
                
                self.log_test(
                    "Campaign Creation",
                    "PASS",
                    f"Campaign ID: {self.campaign_id}, Features: {', '.join(features)}",
                    {"campaign_id": self.campaign_id, "features": features}
                )
                return True
            else:
                error_detail = response.text
                self.log_test("Campaign Creation", "FAIL", f"HTTP {response.status_code}: {error_detail}")
                return False
                
        except Exception as e:
            self.log_test("Campaign Creation", "FAIL", f"Error: {str(e)}")
            return False
    
    def test_campaign_status(self):
        """Test 3: Campaign Status Monitoring (V2 equivalent)"""
        print("\nğŸ”§ TEST 3: Campaign Status Monitoring")
        
        if not self.campaign_id:
            self.log_test("Campaign Status", "SKIP", "No campaign ID available")
            return False
        
        try:
            # Test existing campaign retrieval
            response = requests.get(f"{self.base_url}/api/v1/campaigns/{self.campaign_id}", timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                # Simulate V2 status monitoring features
                context_features = []
                if "campaign_id" in data:
                    context_features.append("Campaign tracking")
                if "business_analysis" in data:
                    ba = data["business_analysis"]
                    if ba.get("business_description"):
                        context_features.append("Business context preserved")
                    if ba.get("target_audience"):
                        context_features.append("Audience targeting maintained")
                if "social_posts" in data:
                    posts = data["social_posts"]
                    context_features.append(f"Generated content: {len(posts)} posts")
                
                self.log_test(
                    "Campaign Status & Context",
                    "PASS", 
                    f"Context preservation: {', '.join(context_features)}",
                    {"context_features": context_features, "post_count": len(data.get("social_posts", []))}
                )
                return True
            else:
                self.log_test("Campaign Status", "FAIL", f"HTTP {response.status_code}")
                return False
                
        except Exception as e:
            self.log_test("Campaign Status", "FAIL", f"Error: {str(e)}")
            return False
    
    def test_campaign_list(self):
        """Test 4: Campaign List with Memory Stats (V2 equivalent)"""
        print("\nğŸ“Š TEST 4: Campaign List & Management")
        
        try:
            response = requests.get(f"{self.base_url}/api/v1/campaigns/", timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                campaigns = data.get("campaigns", [])
                
                # Validate campaign management features
                management_features = []
                if campaigns:
                    management_features.append(f"Campaign storage: {len(campaigns)} campaigns")
                    
                    # Check if our created campaign is listed
                    found_campaign = any(c.get("campaign_id") == self.campaign_id for c in campaigns)
                    if found_campaign:
                        management_features.append("Campaign persistence verified")
                    
                    # Check for metadata
                    for campaign in campaigns:
                        if "created_at" in campaign:
                            management_features.append("Timestamp tracking")
                            break
                
                self.log_test(
                    "Campaign List & Management",
                    "PASS",
                    f"Management features: {', '.join(management_features)}",
                    {"total_campaigns": len(campaigns), "features": management_features}
                )
                return True
            else:
                self.log_test("Campaign List", "FAIL", f"HTTP {response.status_code}")
                return False
                
        except Exception as e:
            self.log_test("Campaign List", "FAIL", f"Error: {str(e)}")
            return False
    
    def test_content_generation(self):
        """Test 5: Content Generation with Real ADK Agents"""
        print("\nğŸ“ TEST 5: Content Generation")
        
        # Correct payload structure for content generation
        business_context = {
            "company_name": "TechCorp AI",
            "business_description": "AI-powered marketing technology company developing advanced agent-driven solutions.",
            "industry": "Technology",
            "target_audience": "Technology professionals and marketing teams",
            "value_propositions": [
                "Advanced AI-driven content generation",
                "Seamless agent-to-agent communication",
                "Zero-fidelity-loss context preservation"
            ],
            "brand_voice": "Professional, innovative, technical yet accessible",
            "competitive_advantages": [
                "Google ADK v1.6+ integration",
                "Enhanced memory management",
                "Real-time agent collaboration"
            ],
            "key_messaging": [
                "Revolutionizing marketing with AI agents",
                "Persistent context for better results",
                "Next-generation campaign management"
            ]
        }
        
        content_payload = {
            "campaign_type": "service",
            "business_context": business_context,
            "campaign_objective": "Generate awareness about enhanced ADK v1.6+ capabilities and A2A messaging features",
            "creativity_level": 7,
            "post_count": 3,
            "include_hashtags": True
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/api/v1/content/generate",
                json=content_payload,
                timeout=60  # Content generation may take time
            )
            
            if response.status_code == 200:
                data = response.json()
                
                # Validate content generation features
                generation_features = []
                if "posts" in data:
                    posts = data["posts"]
                    generation_features.append(f"Generated {len(posts)} social media posts")
                if "campaign_id" in data:
                    generation_features.append("Campaign linking")
                if "business_context" in data:
                    generation_features.append("Business context integration")
                
                self.log_test(
                    "Content Generation",
                    "PASS",
                    f"ADK agent features: {', '.join(generation_features)}",
                    {"post_count": len(data.get("posts", [])), "features": generation_features}
                )
                return True
            else:
                error_detail = response.text
                self.log_test("Content Generation", "FAIL", f"HTTP {response.status_code}: {error_detail}")
                return False
                
        except Exception as e:
            self.log_test("Content Generation", "FAIL", f"Error: {str(e)}")
            return False
    
    def test_missing_v2_endpoints(self):
        """Test 6: V2 Enhanced Endpoints (Expected to be missing)"""
        print("\nğŸš€ TEST 6: V2 Enhanced Endpoints")
        
        v2_endpoints = [
            ("/api/v2/campaigns/health", "Enhanced health with ADK v1.6+ feature listing"),
            ("/api/v2/campaigns/debug/memory-stats", "Memory statistics for A2A messaging"),
            ("/api/v2/campaigns/list", "Campaign list with memory stats"),
        ]
        
        if self.campaign_id:
            v2_endpoints.extend([
                (f"/api/v2/campaigns/{self.campaign_id}/status", "Enhanced campaign status monitoring"),
                (f"/api/v2/campaigns/{self.campaign_id}/context", "Zero-fidelity-loss context retrieval"),
                (f"/api/v2/campaigns/{self.campaign_id}/messages", "A2A message history"),
            ])
        
        missing_endpoints = []
        
        for endpoint, description in v2_endpoints:
            try:
                response = requests.get(f"{self.base_url}{endpoint}", timeout=5)
                if response.status_code == 404:
                    missing_endpoints.append(f"{endpoint} ({description})")
            except:
                missing_endpoints.append(f"{endpoint} ({description})")
        
        self.log_test(
            "V2 Endpoints Check",
            "SKIP",
            f"Expected missing endpoints: {len(missing_endpoints)}",
            {"missing_endpoints": missing_endpoints}
        )
        
        return len(missing_endpoints) > 0
    
    def validate_user_journey(self):
        """Test 7: Complete User Journey Validation"""
        print("\nğŸ¯ TEST 7: User Journey Validation")
        
        # Analyze test results for user journey completion
        passed_tests = [r for r in self.test_results if r["status"] == "PASS"]
        failed_tests = [r for r in self.test_results if r["status"] == "FAIL"]
        
        journey_steps = {
            "System Health": any("Health Check" in r["test_name"] for r in passed_tests),
            "Campaign Creation": any("Campaign Creation" in r["test_name"] for r in passed_tests),
            "Campaign Management": any("Campaign Status" in r["test_name"] or "Campaign List" in r["test_name"] for r in passed_tests),
            "Content Generation": any("Content Generation" in r["test_name"] for r in passed_tests),
        }
        
        completed_steps = [step for step, completed in journey_steps.items() if completed]
        
        if len(completed_steps) >= 3:
            self.log_test(
                "User Journey Validation",
                "PASS",
                f"Completed steps: {', '.join(completed_steps)}",
                {"completed_steps": completed_steps, "total_steps": len(journey_steps)}
            )
            return True
        else:
            self.log_test(
                "User Journey Validation",
                "FAIL",
                f"Only {len(completed_steps)}/{len(journey_steps)} steps completed",
                {"completed_steps": completed_steps, "failed_steps": len(failed_tests)}
            )
            return False
    
    def generate_comprehensive_report(self):
        """Generate final comprehensive report"""
        print("\n" + "="*80)
        print("ENHANCED ADK v1.6+ API VALIDATION - FINAL REPORT")
        print("="*80)
        
        # Test summary
        passed = len([r for r in self.test_results if r["status"] == "PASS"])
        failed = len([r for r in self.test_results if r["status"] == "FAIL"]) 
        skipped = len([r for r in self.test_results if r["status"] == "SKIP"])
        
        print(f"\nğŸ“Š TEST SUMMARY:")
        print(f"   âœ… Passed: {passed}")
        print(f"   âŒ Failed: {failed}")
        print(f"   â­ï¸ Skipped: {skipped}")
        print(f"   ğŸ“ˆ Success Rate: {(passed/(passed+failed)*100):.1f}%" if (passed+failed) > 0 else "   ğŸ“ˆ Success Rate: N/A")
        
        # Feature assessment
        print(f"\nğŸš€ ADK v1.6+ FEATURE ASSESSMENT:")
        
        working_features = []
        foundation_ready = []
        missing_features = []
        
        # Analyze test results for features
        for result in self.test_results:
            if result["status"] == "PASS":
                if "Health Check" in result["test_name"]:
                    working_features.extend([
                        "âœ… ADK Agent Framework Operational",
                        "âœ… Gemini Integration Active", 
                        "âœ… Session Service (A2A Foundation)",
                        "âœ… Artifact Service (Context Foundation)"
                    ])
                elif "Campaign Creation" in result["test_name"]:
                    working_features.append("âœ… Enhanced Campaign Management")
                    foundation_ready.append("ğŸŸ¡ Campaign Context Preservation")
                elif "Content Generation" in result["test_name"]:
                    working_features.append("âœ… Real ADK Agent Content Generation")
                    foundation_ready.append("ğŸŸ¡ Multi-Agent Workflow Foundation")
        
        # V2 missing features
        v2_result = next((r for r in self.test_results if "V2 Endpoints" in r["test_name"]), None)
        if v2_result and v2_result["status"] == "SKIP":
            missing_features.extend([
                "âŒ V2 Health Endpoint with Feature Listing",
                "âŒ Memory Statistics API", 
                "âŒ A2A Message History Tracking",
                "âŒ Zero-Fidelity-Loss Context API",
                "âŒ Enhanced Campaign Status Monitoring"
            ])
        
        print(f"\n   Currently Working:")
        for feature in working_features:
            print(f"     {feature}")
        
        print(f"\n   Foundation Ready:")
        for feature in foundation_ready:
            print(f"     {feature}")
            
        print(f"\n   Missing V2 Enhancements:")
        for feature in missing_features:
            print(f"     {feature}")
        
        # User journey assessment
        journey_result = next((r for r in self.test_results if "User Journey" in r["test_name"]), None)
        journey_status = journey_result["status"] if journey_result else "UNKNOWN"
        
        print(f"\nğŸ¯ USER JOURNEY STATUS: {journey_status}")
        
        if journey_status == "PASS":
            print(f"   âœ… Core functionality operational")
            print(f"   âœ… Campaign workflow complete")
            print(f"   âœ… Content generation working")
            print(f"   ğŸ”§ Ready for V2 enhancement implementation")
        else:
            print(f"   âš ï¸ Some core functionality issues detected")
        
        # Implementation recommendations
        print(f"\nğŸ“‹ IMPLEMENTATION RECOMMENDATIONS:")
        
        if passed >= 4:  # Most tests passing
            print(f"   1. ğŸ—ï¸ Implement V2 API router structure")
            print(f"   2. ğŸ§  Add memory statistics endpoint")
            print(f"   3. ğŸ’¬ Implement A2A message tracking")
            print(f"   4. ğŸ”„ Build enhanced status monitoring")
            print(f"   5. ğŸ¯ Add zero-fidelity-loss context API")
        else:
            print(f"   1. ğŸ”§ Fix failing V1 endpoints first")
            print(f"   2. âœ… Ensure core campaign workflow stability")
            print(f"   3. ğŸ“‹ Then proceed with V2 implementation")
        
        # Generate return object
        return {
            "summary": {
                "passed": passed,
                "failed": failed, 
                "skipped": skipped,
                "success_rate": (passed/(passed+failed)*100) if (passed+failed) > 0 else 0
            },
            "adk_v16_ready": passed >= 3,
            "user_journey_complete": journey_status == "PASS",
            "campaign_id": self.campaign_id,
            "working_features": working_features,
            "missing_features": missing_features,
            "test_details": self.test_results
        }
    
    def run_full_validation(self):
        """Run complete enhanced API validation suite"""
        print("ğŸš€ ENHANCED ADK v1.6+ API VALIDATION SUITE")
        print("ğŸ¯ Validating enhanced features and V2 endpoint readiness")
        print(f"ğŸŒ Testing against: {self.base_url}")
        print(f"â° Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # Run all tests
            self.test_enhanced_health_check()
            self.test_campaign_creation()
            self.test_campaign_status()
            self.test_campaign_list()
            self.test_content_generation()
            self.test_missing_v2_endpoints()
            self.validate_user_journey()
            
        except KeyboardInterrupt:
            print("\nâš ï¸ Testing interrupted by user")
        except Exception as e:
            print(f"\nâŒ Testing suite failed: {str(e)}")
        
        # Generate and return final report
        return self.generate_comprehensive_report()

if __name__ == "__main__":
    validator = FinalAPIValidator()
    final_report = validator.run_full_validation()
    
    # Save detailed report
    report_path = "/Users/jp/Library/Mobile Documents/com~apple~CloudDocs/Documents/workspaces/video-venture-launch/enhanced_adk_validation_final.json"
    with open(report_path, "w") as f:
        json.dump(final_report, f, indent=2)
    
    print(f"\nğŸ“„ Detailed report saved to: enhanced_adk_validation_final.json")
    
    # Final summary
    if final_report["adk_v16_ready"] and final_report["user_journey_complete"]:
        print(f"\nğŸ‰ VALIDATION COMPLETE: ADK v1.6+ foundation ready for V2 implementation!")
    elif final_report["adk_v16_ready"]:
        print(f"\nâœ… VALIDATION PARTIAL: Core features working, some user journey issues")
    else:
        print(f"\nâš ï¸ VALIDATION INCOMPLETE: Core functionality needs attention")